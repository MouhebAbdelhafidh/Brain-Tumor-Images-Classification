{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhAoi1exHfKg"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib imutils\n",
        "!pip install timm torch torchvision opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQEYgIVUHgN_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import imutils\n",
        "import timm  # EfficientNet is available through the timm library\n",
        "from torchvision.datasets import ImageFolder\n",
        "from google.colab import drive\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision.models as models\n",
        "import random\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzNsnH6YHinS"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "%run /content/Brain-Tumor-Images-Classification/Data-Preprocessing/Brain_tumor_data_preprocessing.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X61wZWV_Hi-W"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "%run /content/Brain-Tumor-Images-Classification/Utils/Save_Load__Model.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNLkcm-QHkGi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load pre-trained VGG16 model\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer for your number of classes\n",
        "num_ftrs = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "# Set device to CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Freeze all layers except the final classifier\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# Unfreeze the final classifier layer\n",
        "for param in model.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Pass only the parameters of the final layer to the optimizer\n",
        "optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader):.4f}\")\n",
        "    # Save checkpoint after each epoch\n",
        "    checkpoint = {\n",
        "       'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': running_loss / len(train_loader)\n",
        "    }\n",
        "    checkpoint_path = \"/content/drive/My Drive/vgg16_brain_tumor_checkpoint.pth\"\n",
        "    save_checkpoint(checkpoint, checkpoint_path)\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLHm_HvKH2pz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# Function to test a random image\n",
        "def test_random_image(model, test_loader, device, class_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Get a random sample from the test_loader\n",
        "    dataiter = iter(test_loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    # Select a random image and its corresponding label\n",
        "    idx = random.randint(0, len(images) - 1)\n",
        "    img = images[idx].unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "    true_label = labels[idx].item()\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        output = model(img)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    predicted_label = predicted.item()\n",
        "\n",
        "    # Convert the image back to a format for display\n",
        "    img = img.squeeze().cpu().numpy().transpose(1, 2, 0)  # Convert to HWC format\n",
        "\n",
        "    # Display the image along with predicted and actual labels\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {class_names[predicted_label]} | Actual: {class_names[true_label]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Print the actual and predicted labels\n",
        "    print(f\"Predicted Label: {class_names[predicted_label]}\")\n",
        "    print(f\"Actual Label: {class_names[true_label]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiLFT6MbH4N4"
      },
      "outputs": [],
      "source": [
        "# Call the function to test on a random image\n",
        "test_random_image(model, test_loader, device, class_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
